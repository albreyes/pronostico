{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "name": "Predicción Generadores.ipynb",
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/albreyes/pronostico/blob/main/Predicci%C3%B3n_Generadores.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzIMp716htT4"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.estimator import Estimator\n",
        "from sklearn.preprocessing import QuantileTransformer\n",
        "from typing import List\n",
        "from pprint import pprint\n",
        "\n",
        "tf.autograph.set_verbosity(0)\n",
        "pd.set_option('display.max_rows', 8)\n",
        "\n",
        "from os import path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HmhNd7EmeQ3"
      },
      "source": [
        "# !pip freeze | grep tensorflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7OTxKy7kNgt"
      },
      "source": [
        "# !unzip model_1_3_8_6_7.zip\n",
        "# !mv content/model_1_3_8_6_7/ model_1_3_8_6_7\n",
        "# !rm -r content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ELECBcuihtUZ"
      },
      "source": [
        "# data_path = path.join('datos', 'potencia_velocidad')\n",
        "data_path = ''\n",
        "\n",
        "rename_cols = {\n",
        "    'Time': 'time',\n",
        "    'Avg Wind Speed(m/s)': 'wind_speed',\n",
        "    'Avg Active Power (kW)': 'active_power',\n",
        "    'last time Energy Yield(h)': 'energy_yield',\n",
        "    'Avg Yaw Position(deg)': 'yaw',\n",
        "}\n",
        "\n",
        "cols = [\n",
        "    # 'time',\n",
        "    'wind_speed',\n",
        "    'active_power',\n",
        "    'month',\n",
        "    'day',\n",
        "    'hour',\n",
        "    'minute',\n",
        "    # 'yaw_sin',\n",
        "    # 'yaw_cos',\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "p4tQZNhJhtUt"
      },
      "source": [
        "def get_nth_generator_data(n: int):\n",
        "    file_name = f'generador_{n}.hdf'\n",
        "    file_path = path.join(data_path, file_name)\n",
        "    df = pd.read_hdf(file_path, 'df')\n",
        "    # Get features\n",
        "    df.rename(columns=rename_cols, inplace=True)\n",
        "    df['month'] = df.time.dt.month\n",
        "    df['day'] = df.time.dt.day\n",
        "    df['hour'] = df.time.dt.hour\n",
        "    df['minute'] = df.time.dt.minute\n",
        "    df.set_index('time', inplace=True)\n",
        "    # df['yaw_sin'] = np.sin(2 * np.pi * df.yaw / 360)\n",
        "    # df['yaw_cos'] = np.cos(2 * np.pi * df.yaw / 360)\n",
        "    return df[cols].dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYWQiu7ghaxB"
      },
      "source": [
        "# df = get_nth_generator_data(9)\n",
        "# df.loc[df.index.to_series() < '2014-01-01']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "GwlDnTtwhtU8"
      },
      "source": [
        "# Preprocesamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "8ZZCRB36htU_"
      },
      "source": [
        "PAST_HISTORY = 7 * 24\n",
        "# Data is given in 10 minute frames\n",
        "HOUR_RESOLUTION = 6\n",
        "\n",
        "FUTURE_TARGET = 24\n",
        "\n",
        "series_cols = [\n",
        "    'wind_speed',\n",
        "    # 'active_power',\n",
        "]\n",
        "\n",
        "categ_cols = [\n",
        "    'month',\n",
        "    'day',\n",
        "    'hour',\n",
        "    'minute',\n",
        "]\n",
        "\n",
        "target_cols = [\n",
        "    'wind_speed',\n",
        "    # 'active_power',\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "eJT1DLK9htXC"
      },
      "source": [
        "## Datos de entrenamiento, evaluación y validación"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "8sZzeQRDhtXE"
      },
      "source": [
        "TRAIN_SPLIT = 100000\n",
        "BUFFER_SIZE = 8000\n",
        "BATCH_SIZE = 64\n",
        "EVALUATION_INTERVAL = 50\n",
        "EPOCHS = 20\n",
        "VALIDATION_STEPS = 100\n",
        "PATIENCE = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "1NvvifblhtXP"
      },
      "source": [
        "def data_fn(mode, n_generator):\n",
        "    target_batch = lambda window: window.batch(FUTURE_TARGET)\n",
        "    ts_batch = lambda window: window.batch(PAST_HISTORY * HOUR_RESOLUTION)\n",
        "\n",
        "    def get_ts_data(df):\n",
        "        df_ts = df[series_cols]\n",
        "        return tf.data.Dataset.from_tensor_slices(df_ts)\\\n",
        "            .window(PAST_HISTORY * HOUR_RESOLUTION, 1, 1, True)\\\n",
        "            .flat_map(ts_batch)\n",
        "\n",
        "    def get_cat_data(df):\n",
        "        df_cat = df[categ_cols][PAST_HISTORY * HOUR_RESOLUTION - 1:-(FUTURE_TARGET * HOUR_RESOLUTION)]\n",
        "        return tf.data.Dataset.from_tensor_slices(df_cat), len(df_cat)\n",
        "\n",
        "    def get_target_data(df, dataset_size):\n",
        "        df_target = df[target_cols][PAST_HISTORY * HOUR_RESOLUTION:]\n",
        "        df_target = df_target.rolling(HOUR_RESOLUTION).mean().dropna()\n",
        "        return tf.data.Dataset.from_tensor_slices(df_target)\\\n",
        "            .window(FUTURE_TARGET, 1, 1, True)\\\n",
        "            .flat_map(target_batch)\\\n",
        "            .take(dataset_size)\n",
        "\n",
        "    def data_tx(d1, d2, t):\n",
        "        return {\"categorical_input\": d1, \"timeseries_input\": d2}, t\n",
        "\n",
        "    def get_dataset(df):\n",
        "        time_series_data = get_ts_data(df)\n",
        "        date_data, dataset_size = get_cat_data(df)\n",
        "        target_data = get_target_data(df, dataset_size)\n",
        "        return tf.data.Dataset.zip((date_data, time_series_data, target_data))\\\n",
        "                              .map(data_tx)\n",
        "\n",
        "    if isinstance(n_generator, List):\n",
        "        generator = n_generator[0]\n",
        "        df = get_nth_generator_data(generator)\n",
        "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "            df = df.loc[df.index.to_series() < '2014-01-01']\n",
        "        elif mode == tf.estimator.ModeKeys.EVAL or mode == tf.estimator.ModeKeys.PREDICT:\n",
        "            df = df.loc[df.index.to_series() >= '2014-01-01']\n",
        "        dataset = get_dataset(df)\n",
        "        for generator in n_generator[1:]:\n",
        "            df = get_nth_generator_data(generator)\n",
        "            if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "                df = df.loc[df.index.to_series() < '2014-01-01']\n",
        "            elif mode == tf.estimator.ModeKeys.EVAL or mode == tf.estimator.ModeKeys.PREDICT:\n",
        "                df = df.loc[df.index.to_series() >= '2014-01-01']\n",
        "            dataset_i = get_dataset(df)\n",
        "            dataset = dataset.concatenate(dataset_i)\n",
        "    else:\n",
        "        df = get_nth_generator_data(n_generator)\n",
        "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "            df = df.loc[df.index.to_series() < '2014-01-01']\n",
        "        elif mode == tf.estimator.ModeKeys.EVAL or mode == tf.estimator.ModeKeys.PREDICT:\n",
        "            df = df.loc[df.index.to_series() >= '2014-01-01']\n",
        "        dataset = get_dataset(df)\n",
        "\n",
        "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "        train_data = dataset.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
        "        return train_data\n",
        "\n",
        "    elif mode == tf.estimator.ModeKeys.EVAL:\n",
        "        val_data = dataset.batch(BATCH_SIZE)\n",
        "        return val_data\n",
        "\n",
        "    elif mode == tf.estimator.ModeKeys.PREDICT:\n",
        "        pred_data = dataset.batch(1)\n",
        "        return pred_data\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "vs5JshGZhtXb"
      },
      "source": [
        "# Modelo\n",
        "\n",
        "## Modelo de dos caminos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "NTHG0w6OhtXd"
      },
      "source": [
        "keras.backend.clear_session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "LnsupSdQhtXs"
      },
      "source": [
        "TS_INPUTS = PAST_HISTORY * HOUR_RESOLUTION\n",
        "\n",
        "# Dense Neural Network Path\n",
        "input_ct = keras.Input(\n",
        "    shape=(len(categ_cols),),\n",
        "    name='vector_input')\n",
        "\n",
        "# Recurrent Neural Network Path\n",
        "input_ts = keras.Input(\n",
        "    shape=(TS_INPUTS, len(series_cols)),\n",
        "    name='timeseries_input')\n",
        "\n",
        "x_ts = layers.GRU(FUTURE_TARGET * HOUR_RESOLUTION, return_sequences=True)(input_ts)\n",
        "x_ts = layers.GRU(FUTURE_TARGET, return_sequences=False)(input_ts)\n",
        "\n",
        "x_ct = layers.Dense(2)(input_ct)\n",
        "\n",
        "x = layers.Concatenate(axis=1)([x_ts, x_ct])\n",
        "x = layers.Dense(FUTURE_TARGET)(x)\n",
        "# Last layer without return sequences and ReLU activation\n",
        "outputs = layers.Dense(FUTURE_TARGET)(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "86XlHAy6htX7"
      },
      "source": [
        "model = keras.models.Model(inputs=[input_ct, input_ts], outputs=outputs)\n",
        "\n",
        "keras.utils.plot_model(model, \"Modelo RNN dos caminos.png\", show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "C9-pxmCEhtYH"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n",
          "is_executing": true
        },
        "id": "Jy0U3ZfohtYT"
      },
      "source": [
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='mse',\n",
        "    metrics=['mse', 'mae', 'mape'],\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "F4Bnkv2OhtYe"
      },
      "source": [
        "n_generator = [1, 3, 8, 6, 7]\n",
        "\n",
        "# early_stopping = keras.callbacks.EarlyStopping(monitor='loss', patience=PATIENCE)\n",
        "\n",
        "# history = model.fit(data_fn(tf.estimator.ModeKeys.TRAIN, n_generator),\n",
        "#                     epochs=EPOCHS,\n",
        "#                     steps_per_epoch=EVALUATION_INTERVAL,\n",
        "#                     validation_data=data_fn(tf.estimator.ModeKeys.EVAL, n_generator),\n",
        "#                     validation_steps=VALIDATION_STEPS,\n",
        "#                     verbose=2)\n",
        "\n",
        "keras_estimator = tf.keras.estimator.model_to_estimator(\n",
        "    keras_model=model,\n",
        "    model_dir=f'model_{\"_\".join([str(gen) for gen in n_generator])}',\n",
        "    config = tf.estimator.RunConfig(\n",
        "        tf_random_seed=1,\n",
        "        save_checkpoints_steps=EVALUATION_INTERVAL,\n",
        "        keep_checkpoint_max=10,\n",
        "    )\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iy266K5Y0425"
      },
      "source": [
        "# list(data_fn(tf.estimator.ModeKeys.EVAL, n_generator).take(1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyYNjwA2t1MC"
      },
      "source": [
        "train_spec = tf.estimator.TrainSpec(\n",
        "    input_fn=lambda: data_fn(tf.estimator.ModeKeys.TRAIN, n_generator),\n",
        "    max_steps=500)\n",
        "\n",
        "eval_spec = tf.estimator.EvalSpec(\n",
        "    input_fn=lambda: data_fn(tf.estimator.ModeKeys.EVAL, n_generator),\n",
        "    throttle_secs=60)\n",
        "\n",
        "tf.estimator.train_and_evaluate(keras_estimator, train_spec, eval_spec)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxehW7wwuSb0"
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O56FHcD3une6"
      },
      "source": [
        "%tensorboard --logdir /content/model_1_3_8_6_7/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ua9UE4M5po1g"
      },
      "source": [
        "# !zip -r /content/model_1_3_8_6_7.zip /content/model_1_3_8_6_7"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-GF6iY7jBHh"
      },
      "source": [
        "# !rm -r /content/model_1_3_8_6_7"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MM1p7gRWu-Qx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xy46EMumFTAU"
      },
      "source": [
        "def create_time_steps(length):\n",
        "    return list(range(-length, 0))\n",
        "\n",
        "def multi_step_plot(history, true_future, prediction, title):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    num_in = create_time_steps(len(history))\n",
        "    num_out = len(true_future)\n",
        "\n",
        "    plt.plot(num_in, np.array(history), label='Historia')\n",
        "    plt.plot(np.arange(num_out), np.array(true_future), 'bo',\n",
        "              label='Verdadero Futuro')\n",
        "    if prediction.any():\n",
        "        plt.plot(np.arange(num_out), np.array(prediction), 'ro',\n",
        "                 label='Predicción')\n",
        "    plt.legend(loc='upper left')\n",
        "    plt.ylabel('Velocidad del viento (m/s)')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(title)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rwkq5A_AB01G"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Q-D0P3FD9SL"
      },
      "source": [
        "dataset_take = data_fn(tf.estimator.ModeKeys.PREDICT, n_generator).take(1)\n",
        "x = list(dataset_take.as_numpy_iterator())\n",
        "input_data, target_data = x[0]\n",
        "past_history = input_data['timeseries_input'][0][:, 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHXdMwDjJ5Bn"
      },
      "source": [
        "true_future = target_data[0][:, 0]\n",
        "# true_future\n",
        "predictor = keras_estimator.predict(lambda: data_fn(tf.estimator.ModeKeys.PREDICT, n_generator))\n",
        "# next(predictor)\n",
        "prediction = next(predictor)\n",
        "prediction = prediction['dense_2']\n",
        "# prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfMvX_GJ2kCW"
      },
      "source": [
        "# prediction = prediction['dense_3']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8T4RXSaoGSsA"
      },
      "source": [
        "# true_future = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKmfqaxgHLlG"
      },
      "source": [
        "# past_history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MSPa8AgHXSF"
      },
      "source": [
        "multi_step_plot(past_history, true_future, prediction, 'prediction total history')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZUNGvrRLXo_"
      },
      "source": [
        "multi_step_plot([], true_future, prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiOfMKCbGzEM"
      },
      "source": [
        "multi_step_plot(past_history[850:], true_future, prediction, 'zoomed in prediction')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ish5Rtw_AFVy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRei7Sxa_-A9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}